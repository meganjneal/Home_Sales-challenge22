{"cells": [{"cell_type": "markdown", "id": "f6e9a658", "metadata": {}, "source": "# Home Sales Analysis - Challenge 22\n*Student: Megan Neal*\n*Instructor: Brandon Knox*\n\nThis notebook analyzes home sales data using PySpark SQL functions."}, {"cell_type": "code", "execution_count": null, "id": "a8e117ea", "metadata": {"trusted": false}, "outputs": [], "source": "# Import necessary packages\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import round\nimport time\n\n# Create a SparkSession\nspark = SparkSession.builder.appName(\"HomeSalesAnalysis\").getOrCreate()\nprint(\"SparkSession initialized successfully!\")"}, {"cell_type": "code", "execution_count": null, "id": "8d0e1837", "metadata": {"trusted": false}, "outputs": [], "source": "# Read the home sales data\nhome_sales_df = spark.read.option(\"header\", \"true\").csv(\"home_sales_revised.csv\")\n\n# Create temporary table\nhome_sales_df.createOrReplaceTempView(\"home_sales\")\nprint(\"Data loaded and temporary table created! Preview of the data:\")\nhome_sales_df.show(5)"}, {"cell_type": "markdown", "id": "35ae2364", "metadata": {}, "source": "## Query 1: Average price of 4-bedroom houses by year"}, {"cell_type": "code", "execution_count": null, "id": "20807a9a", "metadata": {"trusted": false}, "outputs": [], "source": "# Find average price of 4-bedroom houses by year\nquery1 = '''\n    SELECT \n        YEAR(date_built) as year_built,\n        ROUND(AVG(price), 2) as avg_price\n    FROM home_sales\n    WHERE bedrooms = 4\n    GROUP BY YEAR(date_built)\n    ORDER BY year_built\n'''\nresult1 = spark.sql(query1)\nprint(\"Average price of 4-bedroom houses by year:\")\nresult1.show()"}, {"cell_type": "markdown", "id": "61265ff5", "metadata": {}, "source": "## Query 2: Average price of homes with 3 beds and 3 baths by year"}, {"cell_type": "code", "execution_count": null, "id": "ce3c7a9f", "metadata": {"trusted": false}, "outputs": [], "source": "# Average price by year for 3 bed, 3 bath homes\nquery2 = '''\n    SELECT \n        YEAR(date_built) as year_built,\n        ROUND(AVG(price), 2) as avg_price\n    FROM home_sales\n    WHERE bedrooms = 3 \n    AND bathrooms = 3\n    GROUP BY YEAR(date_built)\n    ORDER BY year_built\n'''\nresult2 = spark.sql(query2)\nprint(\"Average price of 3-bed, 3-bath homes by year:\")\nresult2.show()"}, {"cell_type": "markdown", "id": "81a856e2", "metadata": {}, "source": "## Query 3: Average price of homes with specific criteria by year"}, {"cell_type": "code", "execution_count": null, "id": "9e4a3756", "metadata": {"trusted": false}, "outputs": [], "source": "# Average price for homes with specific criteria\nquery3 = '''\n    SELECT \n        YEAR(date_built) as year_built,\n        ROUND(AVG(price), 2) as avg_price\n    FROM home_sales\n    WHERE bedrooms = 3 \n    AND bathrooms = 3 \n    AND floors = 2 \n    AND sqft_living >= 2000\n    GROUP BY YEAR(date_built)\n    ORDER BY year_built\n'''\nresult3 = spark.sql(query3)\nprint(\"Average price of homes meeting specific criteria by year:\")\nresult3.show()"}, {"cell_type": "markdown", "id": "89bf4474", "metadata": {}, "source": "## Query 4: Average price by view rating for expensive homes"}, {"cell_type": "code", "execution_count": null, "id": "81de7630", "metadata": {"trusted": false}, "outputs": [], "source": "# Measure runtime for uncached query\nstart_time = time.time()\n\nquery4 = '''\n    SELECT \n        view,\n        ROUND(AVG(price), 2) as avg_price\n    FROM home_sales\n    GROUP BY view\n    HAVING AVG(price) >= 350000\n    ORDER BY view\n'''\nresult4 = spark.sql(query4)\nprint(\"Average price by view rating (uncached):\")\nresult4.show()\n\nend_time = time.time()\nprint(\"Runtime without caching: \", round(end_time - start_time, 2), \"seconds\")"}, {"cell_type": "markdown", "id": "6ed46333", "metadata": {}, "source": "## Cache the temporary table"}, {"cell_type": "code", "execution_count": null, "id": "df47e275", "metadata": {"trusted": false}, "outputs": [], "source": "# Cache the temporary table\nspark.catalog.cacheTable(\"home_sales\")\n\n# Verify the table is cached\nis_cached = spark.catalog.isCached(\"home_sales\")\nprint(\"Is table cached?\", is_cached)\n\n# Run the query on cached data\nstart_time = time.time()\ncached_result = spark.sql(query4)\nprint(\"\nAverage price by view rating (cached):\")\ncached_result.show()\nend_time = time.time()\nprint(\"Runtime with caching: \", round(end_time - start_time, 2), \"seconds\")"}, {"cell_type": "markdown", "id": "4d479643", "metadata": {}, "source": "## Create parquet table"}, {"cell_type": "code", "execution_count": null, "id": "14396ed2", "metadata": {"trusted": false}, "outputs": [], "source": "# Partition by date_built and save as parquet\nhome_sales_df.write.partitionBy(\"date_built\").mode(\"overwrite\").parquet(\"./home_sales_partitioned_parquet\")\n\n# Create temporary table from parquet data\nparquet_df = spark.read.parquet(\"./home_sales_partitioned_parquet\")\nparquet_df.createOrReplaceTempView(\"home_sales_parquet\")\n\n# Run query on parquet table\nstart_time = time.time()\nparquet_result = spark.sql(query4.replace(\"home_sales\", \"home_sales_parquet\"))\nprint(\"Average price by view rating (parquet):\")\nparquet_result.show()\nend_time = time.time()\nprint(\"Runtime with parquet: \", round(end_time - start_time, 2), \"seconds\")"}, {"cell_type": "markdown", "id": "05382703", "metadata": {}, "source": "## Uncache the temporary table"}, {"cell_type": "code", "execution_count": null, "id": "02463ec8", "metadata": {"trusted": false}, "outputs": [], "source": "# Uncache the temporary table\nspark.catalog.uncacheTable(\"home_sales\")\n\n# Verify it is uncached\nis_cached = spark.catalog.isCached(\"home_sales\")\nprint(\"Is table still cached?\", is_cached)"}], "metadata": {}, "nbformat": 4, "nbformat_minor": 5}